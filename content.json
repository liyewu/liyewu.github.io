{"meta":{"title":"MIND YOUR CODING","subtitle":"","description":"","author":"LIYE WU","url":"https://liyewu.github.io","root":"/"},"pages":[{"title":"about","date":"2020-04-17T07:53:30.000Z","updated":"2020-04-17T07:53:30.146Z","comments":true,"path":"about/index.html","permalink":"https://liyewu.github.io/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-04-17T07:53:38.000Z","updated":"2020-04-17T07:53:38.126Z","comments":true,"path":"tags/index.html","permalink":"https://liyewu.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"线性判别分析-OpenCV实现","slug":"线性判别分析-OpenCV实现","date":"2020-05-08T07:09:05.000Z","updated":"2020-05-12T08:34:41.791Z","comments":true,"path":"2020/05/08/线性判别分析-OpenCV实现/","link":"","permalink":"https://liyewu.github.io/2020/05/08/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90-OpenCV%E5%AE%9E%E7%8E%B0/","excerpt":"&emsp;&emsp;线性判别分析(LDA)是模式识别中的经典算法，其主要思想是将高维的样本投影到低维的特征空间，从而达到维度压缩及信息分类的效果。投影后使得样本在新的空间里有着最大的类间距离及最小的类内距离。","text":"&emsp;&emsp;线性判别分析(LDA)是模式识别中的经典算法，其主要思想是将高维的样本投影到低维的特征空间，从而达到维度压缩及信息分类的效果。投影后使得样本在新的空间里有着最大的类间距离及最小的类内距离。 LDA的优缺点&emsp;&emsp;LDA既可以用来降维也可以用来分类。在进行图像识别的数据分析时，LDA是一个有力的工具，其优缺点如下： 优点 * 在降维的过程中充分利用了类别的先验知识，PCA等无监督学习则没有使用这些先验知识； LDA方法在样本分类信息严重依赖均值而不是方差的时候，比PCA之类的方法较优。 缺点 * LDA与PCA都不适合对非高斯分布的数据进行降维； LDA降维最多降低到类别数k-1的维数，如果我们降维的维度大于k-1，则不能使用LDA，目前有一些LDA改进版可绕过这个问题； LDA存在过度拟合数据的问题。 LDA与PCA&emsp;&emsp;LDA与PCA都是降维的方法，有很多相似的地方： 两者降维都基于矩阵分解的思想； 两者都假设数据符合高斯分布。&emsp;&emsp;两者的不同点如下： LDA是有监督的降维方法，PCA是无监督的降维方法； LDA降维最多降到类别墅k-1的维数，而PCA没有限制； LDA不仅可以降维，还可以用于分类； LDA选择分类性能最好的投影方法，而PCA选择样本点投影具有最大方差的方向。 OpenCV实现&emsp;&emsp;使用OpenCV进行LDA分类的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107const int kClassNum &#x3D; 2;const int kWidth &#x3D; 512, kHeight &#x3D; 512;Vec3b red(0, 0, 255), green(0, 255, 0), blue(255, 0, 0);Mat image &#x3D; Mat::zeros(kHeight, kWidth, CV_8UC3);int labels[150] &#x3D; &#123; 0 &#125;;for (size_t i &#x3D; 0; i &lt; 75; i++)&#123; labels[i] &#x3D; 0;&#125;for (size_t i &#x3D; 75; i &lt; 150; i++)&#123; labels[i] &#x3D; 1;&#125;std::vector&lt;int&gt; trainResponse;for (size_t i &#x3D; 0; i &lt; 150; i++)&#123; trainResponse.push_back(labels[i]);&#125;double trainDataArray[150][2];RNG rng;for (size_t i &#x3D; 0; i &lt; 75; i++)&#123; trainDataArray[i][0] &#x3D; 350 + rng.gaussian(30); trainDataArray[i][1] &#x3D; 350 + rng.gaussian(30);&#125;for (size_t i &#x3D; 75; i &lt; 150; i++)&#123; trainDataArray[i][0] &#x3D; 150 + rng.gaussian(30); trainDataArray[i][1] &#x3D; 150 + rng.gaussian(30);&#125;Mat trainDataMat(150, 2, CV_64FC1, trainDataArray);LDA lda(trainDataMat, trainResponse, kClassNum - 1);Mat eigenVector &#x3D; lda.eigenvectors().clone();vector&lt;Mat&gt; classMean(kClassNum);vector&lt;int&gt; classCount(kClassNum);for (size_t i &#x3D; 0; i &lt; kClassNum; i++)&#123; classMean[i] &#x3D; Mat::zeros(1, trainDataMat.cols, CV_64FC1); classCount[i] &#x3D; 0;&#125;Mat sample;for (size_t i &#x3D; 0; i &lt; trainDataMat.rows; i++)&#123; sample &#x3D; trainDataMat.row(i); add(classMean[labels[i]], sample, classMean[labels[i]]); classCount[labels[i]]++;&#125;for (size_t i &#x3D; 0; i &lt; kClassNum; i++)&#123; classMean[i].convertTo(classMean[i], CV_64FC1, 1.0 &#x2F; static_cast&lt;float&gt;(classCount[i]));&#125;vector&lt;Mat&gt; cluster(kClassNum);for (size_t i &#x3D; 0; i &lt; kClassNum; i++)&#123; cluster[i] &#x3D; classMean[i] * eigenVector;&#125;for (size_t i &#x3D; 0; i &lt; image.rows; i++)&#123; for (size_t j &#x3D; 0; j &lt; image.cols; j++) &#123; sample &#x3D; (Mat_&lt;double&gt;(1, 2) &lt;&lt; j, i); Mat projection &#x3D; Mat::zeros(1, 1, CV_64FC1); projection &#x3D; sample*eigenVector; double temp &#x3D; projection.ptr&lt;double&gt;(0)[0]; int response &#x3D; (fabs(temp - cluster[0].ptr&lt;double&gt;(0)[0]) &lt; fabs(temp - cluster[1].ptr&lt;double&gt;(0)[0])) ? 0 : 1; if (response &#x3D;&#x3D; 0) &#123; image.at&lt;Vec3b&gt;(i, j) &#x3D; green; &#125; else &#123; image.at&lt;Vec3b&gt;(i, j) &#x3D; blue; &#125; &#125;&#125;for (size_t i &#x3D; 0; i &lt; trainDataMat.rows; i++)&#123; const double* v &#x3D; trainDataMat.ptr&lt;double&gt;(i); Point pt &#x3D; Point((int)v[0], (int)v[1]); if (labels[i] &#x3D;&#x3D; 0) &#123; circle(image, pt, 5, Scalar::all(0), -1, 8); &#125; else &#123; circle(image, pt, 5, Scalar::all(255), -1, 8); &#125;&#125;imshow(&quot;LDA classifier demo&quot;, image);waitKey(0);return 0; &emsp;&emsp;分类结果如下图：","categories":[],"tags":[{"name":"线性判别","slug":"线性判别","permalink":"https://liyewu.github.io/tags/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB/"},{"name":"主成分分析","slug":"主成分分析","permalink":"https://liyewu.github.io/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"},{"name":"分类算法","slug":"分类算法","permalink":"https://liyewu.github.io/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"},{"name":"LDA，OpenCV","slug":"LDA，OpenCV","permalink":"https://liyewu.github.io/tags/LDA%EF%BC%8COpenCV/"}]},{"title":"OpenCV贝叶斯分类","slug":"OpenCV贝叶斯分类","date":"2020-04-28T09:35:19.000Z","updated":"2020-05-06T08:48:32.410Z","comments":true,"path":"2020/04/28/OpenCV贝叶斯分类/","link":"","permalink":"https://liyewu.github.io/2020/04/28/OpenCV%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB/","excerpt":"&emsp;&emsp;贝叶斯分类器是一种概率模型，是基于贝叶斯公式来解决分类问题。如果样本的特征向量服从某一种概率分布，则可以计算特征向量属于某一个类的条件概率，条件概率最大的类即为分类结果。&emsp;&emsp;使用OpenCV中的贝叶斯分类器进行分类训练，详细代码如下（OpenCV版本为3.4.5，Windows）：","text":"&emsp;&emsp;贝叶斯分类器是一种概率模型，是基于贝叶斯公式来解决分类问题。如果样本的特征向量服从某一种概率分布，则可以计算特征向量属于某一个类的条件概率，条件概率最大的类即为分类结果。&emsp;&emsp;使用OpenCV中的贝叶斯分类器进行分类训练，详细代码如下（OpenCV版本为3.4.5，Windows）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#include &quot;stdafx.h&quot;#include &lt;opencv2\\opencv.hpp&gt;#include &lt;opencv2\\highgui\\highgui.hpp&gt;using namespace std;using namespace cv;using namespace cv::ml;int _tmain(int argc, _TCHAR* argv[])&#123; const int kWidth &#x3D; 512; &#x2F;&#x2F;分类结果图像的宽度 const int kHeight &#x3D; 512; &#x2F;&#x2F;分类结果图像的高度 Vec3b red(0, 0, 255), green(0, 255, 0), blue(255, 0, 0); &#x2F;&#x2F;显示分类结果的3种颜色 Mat image &#x3D; Mat::zeros(kHeight, kWidth, CV_8UC3); int labels[30]; for (size_t i &#x3D; 0; i &lt; 10; i++) &#123; labels[i] &#x3D; 1; &#125; for (size_t i &#x3D; 10; i &lt; 20; i++) &#123; labels[i] &#x3D; 2; &#125; for (size_t i &#x3D; 20; i &lt; 30; i++) &#123; labels[i] &#x3D; 3; &#125; Mat trainResponce(30, 1, CV_32SC1, labels); float trainDataArray[30][2]; RNG rng; for (size_t i &#x3D; 0; i &lt; 10; i++) &#123; trainDataArray[i][0] &#x3D; 250 + static_cast&lt;float&gt;(rng.gaussian(30)); trainDataArray[i][1] &#x3D; 250 + static_cast&lt;float&gt;(rng.gaussian(30)); &#125; for (size_t i &#x3D; 10; i &lt; 20; i++) &#123; trainDataArray[i][0] &#x3D; 150 + static_cast&lt;float&gt;(rng.gaussian(30)); trainDataArray[i][1] &#x3D; 150 + static_cast&lt;float&gt;(rng.gaussian(30)); &#125; for (size_t i &#x3D; 20; i &lt; 30; i++) &#123; trainDataArray[i][0] &#x3D; 320 + static_cast&lt;float&gt;(rng.gaussian(30)); trainDataArray[i][1] &#x3D; 150 + static_cast&lt;float&gt;(rng.gaussian(30)); &#125; Mat trainDataMat(30, 2, CV_32FC1, trainDataArray); Ptr&lt;NormalBayesClassifier&gt; model &#x3D; NormalBayesClassifier::create(); Ptr&lt;TrainData&gt; tData &#x3D; TrainData::create(trainDataMat, ROW_SAMPLE, trainResponce); model-&gt;train(tData); for (size_t i &#x3D; 0; i &lt; image.rows; i++) &#123; for (rsize_t j &#x3D; 0; j &lt; image.cols; j++) &#123; Mat sampleMat &#x3D; (Mat_&lt;float&gt;(1,2) &lt;&lt; j, i); float responce &#x3D; model-&gt;predict(sampleMat); if (responce&#x3D;&#x3D;1) &#123; image.at&lt;Vec3b&gt;(i, j) &#x3D; red; &#125; else if (responce&#x3D;&#x3D;2) &#123; image.at&lt;Vec3b&gt;(i, j) &#x3D; green; &#125; else &#123; image.at&lt;Vec3b&gt;(i, j) &#x3D; blue; &#125; &#125; &#125; for (size_t i &#x3D; 0; i &lt; trainDataMat.rows; i++) &#123; const float* v &#x3D; trainDataMat.ptr&lt;float&gt;(i); Point pt &#x3D; Point((int)v[0], (int)v[1]); if (labels[i]&#x3D;&#x3D;1) &#123; circle(image, pt, 5, Scalar::all(0), -1, 8); &#125; else if (labels[i]&#x3D;&#x3D;2) &#123; circle(image, pt, 5, Scalar::all(128), -1, 8); &#125; else &#123; circle(image, pt, 5, Scalar::all(255), -1, 8); &#125; &#125; imshow(&quot;Bayesian classifier demo&quot;, image); waitKey(0); return 0;&#125; &emsp;&emsp;最终分类结果如下图，可以看出，贝叶斯可以对非线性边界进行划分：","categories":[],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://liyewu.github.io/tags/OpenCV/"},{"name":"贝叶斯","slug":"贝叶斯","permalink":"https://liyewu.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"},{"name":"分类","slug":"分类","permalink":"https://liyewu.github.io/tags/%E5%88%86%E7%B1%BB/"}]},{"title":"常见的聚类算法(一)","slug":"常见的聚类算法-一","date":"2020-04-24T02:13:36.000Z","updated":"2020-05-07T08:27:46.592Z","comments":true,"path":"2020/04/24/常见的聚类算法-一/","link":"","permalink":"https://liyewu.github.io/2020/04/24/%E5%B8%B8%E8%A7%81%E7%9A%84%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-%E4%B8%80/","excerpt":"概念&emsp;&emsp;聚类分析是一种无监督学习，是按照个体之间的特征将其进行分类，让同一个类别内的个体之间具有较高的相似度（类间差异较小），不同类别之间具有较大的差异性（类类差异较大）。 常见的聚类算法&emsp;&emsp;常见的聚类算法由K-means、层次聚类及DBSCAN密度法等。","text":"概念&emsp;&emsp;聚类分析是一种无监督学习，是按照个体之间的特征将其进行分类，让同一个类别内的个体之间具有较高的相似度（类间差异较小），不同类别之间具有较大的差异性（类类差异较大）。 常见的聚类算法&emsp;&emsp;常见的聚类算法由K-means、层次聚类及DBSCAN密度法等。 K-means&emsp;&emsp;其中K代表类别数目，means代表均值算法，K-means即为基于均值算法把数据划分为K个类别。OpenCV中KNN的实现代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101const int kWidth &#x3D; 512; &#x2F;&#x2F;分类结果图像的宽度const int kHeight &#x3D; 512; &#x2F;&#x2F;分类结果图像的高度const int kk &#x3D; 5;Vec3b red(0, 0, 255), green(0, 255, 0), blue(255, 0, 0); &#x2F;&#x2F;显示分类结果的3种颜色Mat image &#x3D; Mat::zeros(kHeight, kWidth, CV_8UC3);int labels[150];for (size_t i &#x3D; 0; i &lt; 50; i++)&#123; labels[i] &#x3D; 1;&#125;for (size_t i &#x3D; 50; i &lt; 100; i++)&#123; labels[i] &#x3D; 2;&#125;for (size_t i &#x3D; 100; i &lt; 150; i++)&#123; labels[i] &#x3D; 3;&#125;Mat trainresponse(150, 1, CV_32SC1, labels);float trainDataArray[150][2];RNG rng;for (size_t i &#x3D; 0; i &lt; 50; i++)&#123; trainDataArray[i][0] &#x3D; 250 + static_cast&lt;float&gt;(rng.gaussian(30)); trainDataArray[i][1] &#x3D; 250 + static_cast&lt;float&gt;(rng.gaussian(30));&#125;for (size_t i &#x3D; 50; i &lt; 100; i++)&#123; trainDataArray[i][0] &#x3D; 150 + static_cast&lt;float&gt;(rng.gaussian(30)); trainDataArray[i][1] &#x3D; 150 + static_cast&lt;float&gt;(rng.gaussian(30));&#125;for (size_t i &#x3D; 100; i &lt; 150; i++)&#123; trainDataArray[i][0] &#x3D; 320 + static_cast&lt;float&gt;(rng.gaussian(30)); trainDataArray[i][1] &#x3D; 150 + static_cast&lt;float&gt;(rng.gaussian(30));&#125;Mat trainDataMat(150, 2, CV_32FC1, trainDataArray);Ptr&lt;KNearest&gt; knn &#x3D; KNearest::create();knn-&gt;train(trainDataMat, ROW_SAMPLE, trainresponse);bool flag &#x3D; knn-&gt;isTrained();if (!flag)&#123; cout &lt;&lt; &quot;Model is not trained!&quot; &lt;&lt; endl;&#125;for (size_t i &#x3D; 0; i &lt; image.rows; i++)&#123; for (size_t j &#x3D; 0; j &lt; image.cols; j++) &#123; Mat sampleMat &#x3D; (Mat_&lt;float&gt;(1, 2) &lt;&lt; j, i); Mat resutlMat; knn-&gt;findNearest(sampleMat, kk, resutlMat); int response &#x3D; (int) ((float*)resutlMat.data)[0]; if (response &#x3D;&#x3D; 1) &#123; image.at&lt;Vec3b&gt;(i, j) &#x3D; red; &#125; else if (response &#x3D;&#x3D; 2) &#123; image.at&lt;Vec3b&gt;(i, j) &#x3D; green; &#125; else &#123; image.at&lt;Vec3b&gt;(i, j) &#x3D; blue; &#125; &#125;&#125;for (size_t i &#x3D; 0; i &lt; trainDataMat.rows; i++)&#123; const float* v &#x3D; trainDataMat.ptr&lt;float&gt;(i); Point pt &#x3D; Point((int)v[0], (int)v[1]); if (labels[i] &#x3D;&#x3D; 1) &#123; circle(image, pt, 5, Scalar::all(0), -1, 8); &#125; else if (labels[i] &#x3D;&#x3D; 2) &#123; circle(image, pt, 5, Scalar::all(128), -1, 8); &#125; else &#123; circle(image, pt, 5, Scalar::all(255), -1, 8); &#125;&#125;imshow(&quot;KNN classifier demo&quot;, image);waitKey(0);return 0; &emsp;&emsp;实现的效果图如下：","categories":[],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://liyewu.github.io/tags/OpenCV/"},{"name":"聚类算法","slug":"聚类算法","permalink":"https://liyewu.github.io/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"},{"name":"聚类分析","slug":"聚类分析","permalink":"https://liyewu.github.io/tags/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"},{"name":"无监督学习","slug":"无监督学习","permalink":"https://liyewu.github.io/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"}]},{"title":"图像增强方法(一)","slug":"图像增强方法-一","date":"2020-04-20T02:55:43.000Z","updated":"2020-04-27T08:51:47.846Z","comments":true,"path":"2020/04/20/图像增强方法-一/","link":"","permalink":"https://liyewu.github.io/2020/04/20/%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95-%E4%B8%80/","excerpt":"直方图的概念理解&emsp;&emsp;电子图像是由像素构成的，图像直方图是反映图像中的像素分布的统计表，因此直方图是图像的一个重要特征。&emsp;&emsp;以8位灰度图举例，在直方图中，第k个灰度级的值就是图像中灰度值为k的像素个数；归一化的直方图就是像素个数除以总得像素数目。","text":"直方图的概念理解&emsp;&emsp;电子图像是由像素构成的，图像直方图是反映图像中的像素分布的统计表，因此直方图是图像的一个重要特征。&emsp;&emsp;以8位灰度图举例，在直方图中，第k个灰度级的值就是图像中灰度值为k的像素个数；归一化的直方图就是像素个数除以总得像素数目。 直方图均衡化 均衡化的基本思想是，不让某个灰度级的像素数量太多，尽量使得每个灰度级的像素数量相等； 均衡化的作用，使得图像的灰度级分布均匀，分布更加广泛，从而提高图像的对比度； 均衡化的优点是，过程可以自动进行，不需要额外的参数，但是拉伸后的图像会存在颗粒感。均衡化的步骤 计算归一化直方图 计算归一化累计直方图fHist[L-1] 计算变换后的灰度值fHist[s]*[L-1] #L为灰度级别，对于8位灰度图即为256，s为变化前的灰度值 局部直方图处理&emsp;&emsp;由于全局的直方图均衡化不考虑局部的特性，因此会忽略掉局部的细节，这在某些时候不是我们所期望的，因此可以考虑使用局部直方图的处理方法。子块直方图的处理方法基本原理就是将图像划分为一个个单独的子块（可重叠可不重叠，不重叠子块存在明显的块效应，因此一般为重叠子块方法），在子块内对像素值进行均衡化操作。这种子块划分的方法主要是为了考虑局部的图像特性，其基本步骤和思想与全局的直方图均衡化类似（可以假设全局的直方图均衡化即是将图像划分为唯一一个子块来处理）。 OpenCV中的均衡化代码&emsp;&emsp;OpenCV中图像均衡化源码为下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758void cv::equalizeHist( InputArray _src, OutputArray _dst )&#123; CV_INSTRUMENT_REGION(); CV_Assert( _src.type() &#x3D;&#x3D; CV_8UC1 ); if (_src.empty()) return; CV_OCL_RUN(_src.dims() &lt;&#x3D; 2 &amp;&amp; _dst.isUMat(), ocl_equalizeHist(_src, _dst)) Mat src &#x3D; _src.getMat(); &#x2F;&#x2F;将传入的参数转换为Mat的结构 _dst.create( src.size(), src.type() ); &#x2F;&#x2F;OutputArray是InputArray的派生类,需要先调用_OutputArray：：create（）为矩阵分配空间 Mat dst &#x3D; _dst.getMat(); CV_OVX_RUN(!ovx::skipSmallImages&lt;VX_KERNEL_EQUALIZE_HISTOGRAM&gt;(src.cols, src.rows), openvx_equalize_hist(src, dst)) Mutex histogramLockInstance; const int hist_sz &#x3D; EqualizeHistCalcHist_Invoker::HIST_SZ; int hist[hist_sz] &#x3D; &#123;0,&#125;; int lut[hist_sz]; EqualizeHistCalcHist_Invoker calcBody(src, hist, &amp;histogramLockInstance); EqualizeHistLut_Invoker lutBody(src, dst, lut); cv::Range heightRange(0, src.rows); &#x2F;&#x2F;高度范围 if(EqualizeHistCalcHist_Invoker::isWorthParallel(src)) &#x2F;&#x2F;图像是否大于等于640*480 parallel_for_(heightRange, calcBody); else calcBody(heightRange); int i &#x3D; 0; while (!hist[i]) ++i; int total &#x3D; (int)src.total(); &#x2F;&#x2F;图像中元素总数 if (hist[i] &#x3D;&#x3D; total) &#123; dst.setTo(i); return; &#125; float scale &#x3D; (hist_sz - 1.f)&#x2F;(total - hist[i]); int sum &#x3D; 0; for (lut[i++] &#x3D; 0; i &lt; hist_sz; ++i) &#123; sum +&#x3D; hist[i]; lut[i] &#x3D; saturate_cast&lt;uchar&gt;(sum * scale); &#x2F;&#x2F;直方图均衡 &#125; if(EqualizeHistLut_Invoker::isWorthParallel(src)) parallel_for_(heightRange, lutBody); else lutBody(heightRange);&#125; &emsp;&emsp;calcBody及lutBody函数的定义如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980void operator()( const cv::Range&amp; rowRange ) const CV_OVERRIDE&#123; int localHistogram[HIST_SZ] &#x3D; &#123;0, &#125;; const size_t sstep &#x3D; src_.step; &#x2F;&#x2F;每行的字节数目 int width &#x3D; src_.cols; int height &#x3D; rowRange.end - rowRange.start; if (src_.isContinuous()) &#123; width *&#x3D; height; height &#x3D; 1; &#125; for (const uchar* ptr &#x3D; src_.ptr&lt;uchar&gt;(rowRange.start); height--; ptr +&#x3D; sstep) &#123; int x &#x3D; 0; for (; x &lt;&#x3D; width - 4; x +&#x3D; 4) &#123; int t0 &#x3D; ptr[x], t1 &#x3D; ptr[x+1]; localHistogram[t0]++; localHistogram[t1]++; t0 &#x3D; ptr[x+2]; t1 &#x3D; ptr[x+3]; localHistogram[t0]++; localHistogram[t1]++; &#125; for (; x &lt; width; ++x) localHistogram[ptr[x]]++; &#125; cv::AutoLock lock(*histogramLock_); for( int i &#x3D; 0; i &lt; HIST_SZ; i++ ) globalHistogram_[i] +&#x3D; localHistogram[i];&#125;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;void operator()( const cv::Range&amp; rowRange ) const CV_OVERRIDE&#123; const size_t sstep &#x3D; src_.step; const size_t dstep &#x3D; dst_.step; int width &#x3D; src_.cols; int height &#x3D; rowRange.end - rowRange.start; int* lut &#x3D; lut_; if (src_.isContinuous() &amp;&amp; dst_.isContinuous()) &#123; width *&#x3D; height; height &#x3D; 1; &#125; const uchar* sptr &#x3D; src_.ptr&lt;uchar&gt;(rowRange.start); uchar* dptr &#x3D; dst_.ptr&lt;uchar&gt;(rowRange.start); for (; height--; sptr +&#x3D; sstep, dptr +&#x3D; dstep) &#123; int x &#x3D; 0; for (; x &lt;&#x3D; width - 4; x +&#x3D; 4) &#123; int v0 &#x3D; sptr[x]; int v1 &#x3D; sptr[x+1]; int x0 &#x3D; lut[v0]; int x1 &#x3D; lut[v1]; dptr[x] &#x3D; (uchar)x0; dptr[x+1] &#x3D; (uchar)x1; v0 &#x3D; sptr[x+2]; v1 &#x3D; sptr[x+3]; x0 &#x3D; lut[v0]; x1 &#x3D; lut[v1]; dptr[x+2] &#x3D; (uchar)x0; dptr[x+3] &#x3D; (uchar)x1; &#125; for (; x &lt; width; ++x) dptr[x] &#x3D; (uchar)lut[sptr[x]]; &#125;&#125;","categories":[],"tags":[{"name":"图像增强","slug":"图像增强","permalink":"https://liyewu.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/"},{"name":"直方图","slug":"直方图","permalink":"https://liyewu.github.io/tags/%E7%9B%B4%E6%96%B9%E5%9B%BE/"},{"name":"均衡化","slug":"均衡化","permalink":"https://liyewu.github.io/tags/%E5%9D%87%E8%A1%A1%E5%8C%96/"}]},{"title":"常用的颜色空间","slug":"常用的颜色空间","date":"2020-04-17T01:05:25.000Z","updated":"2020-04-22T09:29:06.887Z","comments":true,"path":"2020/04/17/常用的颜色空间/","link":"","permalink":"https://liyewu.github.io/2020/04/17/%E5%B8%B8%E7%94%A8%E7%9A%84%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4/","excerpt":"图像处理中的常用颜色空间在日常生活中，我们最常用的颜色空间可能是RGB，知道彩色图像是由这三个通道合成的。但是在图像处理过程中，往往是使用其它的颜色空间，这是因为RGB颜色空间是基于三色合成的原理，但是这种合成的原理在某些情况下并不适用于图像处理，譬如对颜色渐变及明暗变化的图像区域作图像分割等，这个往往需要将RGB图像转化到其它的颜色空间。在图像处理中，常用的颜色空间还要HSV、CMY等。","text":"图像处理中的常用颜色空间在日常生活中，我们最常用的颜色空间可能是RGB，知道彩色图像是由这三个通道合成的。但是在图像处理过程中，往往是使用其它的颜色空间，这是因为RGB颜色空间是基于三色合成的原理，但是这种合成的原理在某些情况下并不适用于图像处理，譬如对颜色渐变及明暗变化的图像区域作图像分割等，这个往往需要将RGB图像转化到其它的颜色空间。在图像处理中，常用的颜色空间还要HSV、CMY等。 RGB颜色空间RGB 空间就是图像颜色由三个颜色通道来确定，这个颜色空间面向电子硬件比较有利，是最常用的颜色空间。但是人眼比较敏感的是光影明暗等变化，这种变化在RGB空间中的数值变化往往是需要三个数值同时做出改变，与人眼的感受相比不够直观。 HSV颜色空间HSV(hue,saturation,value)也叫HSB(hue,saturation,brightness)，其中hue表示色相，saturation为饱和度，value和brightness表示明度。相比于RGB颜色空间，HSV颜色空间更接近人眼对色彩的感知，能直观的表达颜色的明暗、色调和鲜艳程度，一般有利于对指定颜色的物体进行切割。 CMY颜色空间CMY一般可以和RGB颜色空间联系起来认识，不同的是RGB空间是主动发光机理，而CMY是反射光机理，因此一般用于彩色打印等场景。","categories":[],"tags":[{"name":"颜色空间","slug":"颜色空间","permalink":"https://liyewu.github.io/tags/%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4/"}]},{"title":"指针与引用","slug":"指针与引用","date":"2020-04-15T06:33:42.000Z","updated":"2020-04-22T09:29:38.516Z","comments":true,"path":"2020/04/15/指针与引用/","link":"","permalink":"https://liyewu.github.io/2020/04/15/%E6%8C%87%E9%92%88%E4%B8%8E%E5%BC%95%E7%94%A8/","excerpt":"引用与指针的区别引用和指针都是有关地址的概念，指针是指向一块内存地址，它的内容就是所指内存的地址，而引用是某一块内存的另外一个名称。在理解层面的话，引用应该叫做“别名”，专业术语是，引用是没有对象的，指针是一个实体，在使用的时候，引用和指针有以下一些区别：","text":"引用与指针的区别引用和指针都是有关地址的概念，指针是指向一块内存地址，它的内容就是所指内存的地址，而引用是某一块内存的另外一个名称。在理解层面的话，引用应该叫做“别名”，专业术语是，引用是没有对象的，指针是一个实体，在使用的时候，引用和指针有以下一些区别： 1234* 指针初始化可以为空，但是引用初始化必须绑定特定的初始值对象* 指针在使用的过程中可以更改指向的地址，但是引用在初始化后只能从一而终* 引用没有 const，指针可以用const，使用const的指针指向地址不可变* “sizeof+引用”得到的是指向对象的大小， “sizeof+指针”得到的是指针大小 引用的指针与指针的引用 从语言规范上来讲，是没有引用的指针这一说法的，举例如下： 1234int a &#x3D; 0;int *pa &#x3D; &amp;a;int &amp;ra &#x3D; a;int &amp;*pra &#x3D; ra; &#x2F;&#x2F;? 很显然，上例中pra编译器会报错，不允许使用引用的指针。 但是指针的引用确实存在的，同样举例如下： 123456789int a &#x3D; 0;int *pa &#x3D; &amp;a;int &amp;ra &#x3D; a;int *&amp;rpa &#x3D; pa; &#x2F;&#x2F;OKprintf(&quot;addresss a:%d\\n&quot;,(uintptr_t)&amp;a);printf(&quot;addresss pa:%d\\n&quot;,(uintptr_t)&amp;pa);printf(&quot;addresss ra:%d\\n&quot;,(uintptr_t)&amp;ra);printf(&quot;addresss rpa:%d\\n&quot;,(uintptr_t)&amp;rpa); 输出如下： 1234addresss a:6422040addresss pa:6422032addresss ra:6422040addresss rpa:6422032 可以看出，引用的地址就是对应对象的地址。","categories":[],"tags":[{"name":"C/C++","slug":"C-C","permalink":"https://liyewu.github.io/tags/C-C/"},{"name":"指针","slug":"指针","permalink":"https://liyewu.github.io/tags/%E6%8C%87%E9%92%88/"},{"name":"引用","slug":"引用","permalink":"https://liyewu.github.io/tags/%E5%BC%95%E7%94%A8/"}]}],"categories":[],"tags":[{"name":"线性判别","slug":"线性判别","permalink":"https://liyewu.github.io/tags/%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB/"},{"name":"主成分分析","slug":"主成分分析","permalink":"https://liyewu.github.io/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"},{"name":"分类算法","slug":"分类算法","permalink":"https://liyewu.github.io/tags/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"},{"name":"LDA，OpenCV","slug":"LDA，OpenCV","permalink":"https://liyewu.github.io/tags/LDA%EF%BC%8COpenCV/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://liyewu.github.io/tags/OpenCV/"},{"name":"贝叶斯","slug":"贝叶斯","permalink":"https://liyewu.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"},{"name":"分类","slug":"分类","permalink":"https://liyewu.github.io/tags/%E5%88%86%E7%B1%BB/"},{"name":"聚类算法","slug":"聚类算法","permalink":"https://liyewu.github.io/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"},{"name":"聚类分析","slug":"聚类分析","permalink":"https://liyewu.github.io/tags/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"},{"name":"无监督学习","slug":"无监督学习","permalink":"https://liyewu.github.io/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"},{"name":"图像增强","slug":"图像增强","permalink":"https://liyewu.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/"},{"name":"直方图","slug":"直方图","permalink":"https://liyewu.github.io/tags/%E7%9B%B4%E6%96%B9%E5%9B%BE/"},{"name":"均衡化","slug":"均衡化","permalink":"https://liyewu.github.io/tags/%E5%9D%87%E8%A1%A1%E5%8C%96/"},{"name":"颜色空间","slug":"颜色空间","permalink":"https://liyewu.github.io/tags/%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4/"},{"name":"C/C++","slug":"C-C","permalink":"https://liyewu.github.io/tags/C-C/"},{"name":"指针","slug":"指针","permalink":"https://liyewu.github.io/tags/%E6%8C%87%E9%92%88/"},{"name":"引用","slug":"引用","permalink":"https://liyewu.github.io/tags/%E5%BC%95%E7%94%A8/"}]}